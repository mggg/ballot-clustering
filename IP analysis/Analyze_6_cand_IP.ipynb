{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from Clustering_Functions import *\n",
    "from itertools import combinations\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfK = pd.read_pickle('clustering_results.pkl') # heuristic results\n",
    "dfIP = pd.read_json(\"6_cand_all_solutions.json\", orient=\"records\")\n",
    "dfIP_PH = pd.read_json(\"pentland_hills_all_models.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filename', 'num_cands', 'parties', 'method', 'sil', 'cal', 'dav', 'centers', 'bloc_size']\n",
      "['n_candidates', 'election_name', 'model', 'candidates', 'optimum_value', 'centroid_set']\n"
     ]
    }
   ],
   "source": [
    "print(list(dfK.columns))\n",
    "print(list(dfIP.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['continuous_bordaP' 'continuous_hh' 'continuous_rest_bordaP'\n",
      " 'continuous_rest_hh' 'discrete_HH' 'discrete_bordaP']\n",
      "['meanBC' 'meanBA' 'meanH' 'medoBC' 'medoBA' 'medoH' 'slate']\n"
     ]
    }
   ],
   "source": [
    "print(dfIP['model'].unique())\n",
    "print(dfK['method'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create `df` dataframe to hold IP and heuristic results.\n",
    "\n",
    "df = pd.DataFrame(columns=['filename', 'num_cands', 'method', 'proxy', 'technique', \n",
    "                           'centers', 'proxies_of_centers'])\n",
    "\n",
    "# add the IP results to df.\n",
    "D_IP = {\n",
    " 'continuous_bordaP': ('coords','Borda'),\n",
    " 'continuous_hh':('coords','HH'),\n",
    " 'continuous_rest_bordaP':('all','Borda'),\n",
    " 'continuous_rest_hh':('all','HH'),\n",
    " 'discrete_HH': ('cast','HH'),\n",
    " 'discrete_bordaP': ('cast','Borda')}\n",
    "\n",
    "for index in dfIP.index:\n",
    "    method, proxy = D_IP[dfIP['model'][index]]\n",
    "    filename = f\"{dfIP['election_name'][index]}.csv\" \n",
    "    num_cands = dfIP['n_candidates'][index]\n",
    "    proxies_of_centers = dfIP['centroid_set'][index]\n",
    "    technique = f\"{method}_{proxy}\"\n",
    "    if technique  == 'cast_HH': # fix that this model uses +- 1/2 for components instead of +-1\n",
    "        proxies_of_centers = [ [2*x for x in proxy] for proxy in proxies_of_centers]\n",
    "    t = df.shape[0]\n",
    "    df.loc[t] = [filename, num_cands, method, proxy, technique, None, proxies_of_centers]\n",
    "\n",
    "# add the heuristic results to df.\n",
    "filename_list = df['filename'].unique()\n",
    "D_K = {'meanBC': ('Lloyd','Borda'), 'meanH':('Lloyd','HH'), 'medoBC':('PAM','Borda'), 'medoH':('PAM','HH')}\n",
    "for filename in filename_list:\n",
    "    for method_code in D_K.keys():\n",
    "        dfK_sub = dfK[(dfK['filename']==filename) & (dfK['method']==method_code)]\n",
    "        if dfK_sub.shape[0] == 0:\n",
    "            continue\n",
    "        num_cands = dfK_sub['num_cands'].values[0]\n",
    "        method, proxy = D_K[method_code]\n",
    "        technique = f\"{method}_{proxy}\"\n",
    "        centers = dfK_sub['centers'].values[0]\n",
    "        centers = [centers[0], centers[1]] # ensure its a list rather than dictionary\n",
    "        t = df.shape[0]\n",
    "        if method == 'PAM': \n",
    "            df.loc[t] = [filename, num_cands, method, proxy, technique, centers, None]\n",
    "        else: # For Lloyd, centers live in proxy space\n",
    "            df.loc[t] = [filename, num_cands, method, proxy, technique, None, centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 205)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list = df['filename'].unique()\n",
    "len(filename_list), len(df)//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'kmedians' models to df for both Borda and HH proxies.\n",
    "count = 1\n",
    "for filename in filename_list:    \n",
    "    full_filename = f\"../ballot-clustering/scot-elex/6_cands/{filename}\"\n",
    "    print(count, filename)\n",
    "    count +=1\n",
    "    num_cands, election, cand_names, ward = csv_parse(full_filename)\n",
    "    for proxy in ['Borda', 'HH']:\n",
    "        _, centers = kmedians(election, proxy = proxy, return_centroids=True)\n",
    "        technique = f'kMedians_{proxy}'\n",
    "        t = df.shape[0]\n",
    "        df.loc[t] = [filename, num_cands, 'kMedians', proxy, technique, None, centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coords_Borda',\n",
       " 'coords_HH',\n",
       " 'all_Borda',\n",
       " 'all_HH',\n",
       " 'cast_HH',\n",
       " 'cast_Borda',\n",
       " 'Lloyd_Borda',\n",
       " 'Lloyd_HH',\n",
       " 'PAM_Borda',\n",
       " 'PAM_HH',\n",
       " 'kMedians_Borda',\n",
       " 'kMedians_HH']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_list = list(df['technique'].unique())\n",
    "method_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that reverse Borda and HH vectors, and sometimes yield generalized ballots.\n",
    "\n",
    "def Borda_proxy(ballot, num_cands , borda_style='pes', start = 0):\n",
    "    \"\"\"\n",
    "    Returns the Borda vector of the given (simple or generalized) ballot.\n",
    "        \n",
    "    Args:\n",
    "        ballot : a simple or generalized ballot (tuple of integers or of sets of integers). \n",
    "        num_cands : the number of candidates. \n",
    "        borda_style : choice of {'pes', 'avg'}\n",
    "        start : the lowest score awarded; for example, set start=1 if you want a full ballot to award {1,2,...,num_cands} points.\n",
    "     \n",
    "    Returns:\n",
    "        the Borda vector (np.array) of the given generalized ballot.                \n",
    "    \"\"\"\n",
    "\n",
    "    # append set of missing candidates to end of ballot\n",
    "    ballot = list(ballot)\n",
    "    missing_cands = set(range(1,num_cands+1))\n",
    "    for c in ballot:\n",
    "        S = c if type(c) == set else {c}\n",
    "        for x in S:\n",
    "            missing_cands.discard(x)\n",
    "    if len(missing_cands) > 0:\n",
    "        ballot.append(missing_cands)\n",
    "    # compute Borda vector\n",
    "    score_queue = list(range(start, start+num_cands))\n",
    "    to_return = [0 for _ in range(num_cands)]\n",
    "    for c in ballot:\n",
    "        S = c if type(c) == set else {c}\n",
    "        scores = [score_queue.pop() for _ in range(len(S))]\n",
    "        points = np.mean(scores) if borda_style == 'avg' else min(scores)\n",
    "        for x in S:\n",
    "            to_return[x-1] = points\n",
    "\n",
    "    return np.array(to_return)\n",
    "\n",
    "def Reverse_Borda(proxy):\n",
    "    \"\"\" \n",
    "    Returns the generalized ballot corresponding to the given Borda proxy vector.\n",
    "    Returns a simple ballot if possible, otherwise a generalized ballot\n",
    "    Works with either borda_style convention ('pes' or 'avg') \n",
    "    \"\"\"\n",
    "    num_cands = len(proxy)\n",
    "\n",
    "    proxy = list(proxy)\n",
    "    to_return = []\n",
    "    cands_placed = []\n",
    "    while len(cands_placed) < num_cands:\n",
    "        S = [x for x in range(1,num_cands+1) if proxy[x-1]==np.max(proxy)] # best-scoring candidates\n",
    "        cands_placed.extend(S)\n",
    "        to_return.append(set(S))\n",
    "        for x in S:\n",
    "            proxy[x-1] = -1\n",
    "\n",
    "    # return a simple ballot if possible\n",
    "    if all(len(c)==1 for c in to_return[:-1]):\n",
    "        return tuple([list(c)[0] for c in to_return if len(c)==1])\n",
    "    else:\n",
    "        return tuple(to_return)\n",
    "    \n",
    "def HH_proxy(ballot,num_cands):\n",
    "    \"\"\"\n",
    "    Returns the head-to-head proxy vector of the given (simple or generalized) ballot.\n",
    "        \n",
    "    This is a vector with one entry for each pair of candidates ordered in the natural way; namely {(1,2),(1,3),...,(1,n),(2,3),...}. \n",
    "    The entries lie in {-1,0,1} depending on whether the lower-indexed candidate {looses, ties, wins} the head-to-head comparison. \n",
    "\n",
    "    Args:\n",
    "        ballot: a simple or generalized ballot (tuple of integers or of sets of integers).\n",
    "    \n",
    "    Returns:\n",
    "        The head-to-head proxy vector (np.array)\n",
    "    \"\"\"\n",
    "    # append set of missing candidates to end of ballot\n",
    "    ballot = list(ballot)\n",
    "    missing_cands = set(range(1,num_cands+1))\n",
    "    for c in ballot:\n",
    "        S = c if type(c) == set else {c}\n",
    "        for x in S:\n",
    "            missing_cands.discard(x)\n",
    "    if len(missing_cands) > 0:\n",
    "        ballot.append(missing_cands)\n",
    "\n",
    "    M = np.full([num_cands,num_cands], np.nan)\n",
    "\n",
    "    # first place the zeros for ties and build the unpacked ballot\n",
    "    unpacked_ballot = []\n",
    "    for c in ballot:\n",
    "        S = c if type(c) == set else {c}\n",
    "        if len(S)>1:\n",
    "            for x,y in combinations(S,2):\n",
    "                M[x-1,y-1] = 0\n",
    "                M[y-1,x-1] = 0\n",
    "        unpacked_ballot.extend(S)\n",
    "\n",
    "    # now place the -1 and 1 entries\n",
    "    for x,y in combinations(unpacked_ballot,2):\n",
    "        if M[x-1,y-1] != 0:\n",
    "            M[x-1,y-1] = 1\n",
    "            M[y-1,x-1] = -1\n",
    "\n",
    "    # flatten the matrix into a vector\n",
    "    to_return = []\n",
    "    for x,y in combinations(range(num_cands),2):\n",
    "        to_return.append(M[x,y])\n",
    "    return np.array(to_return)\n",
    "\n",
    "def Reverse_HH(proxy):\n",
    "    \"\"\" \n",
    "    Returns the (simple or generalized) ballot corresponding to the given HH proxy vector,\n",
    "    or None if the proxy is inconsistent.\n",
    "    Any positive entry (not just +1) is interpreted as a win for the lower-indexed candidate, and any negative entry a loss,\n",
    "    while a zero entry indicates a tie.\n",
    "    Returns a simple ballot if possible, otherwise a generalized ballot.\n",
    "    \"\"\"\n",
    "    # determine the number of candidates\n",
    "    proxy = list(proxy)\n",
    "    A = np.sqrt(1+8*len(proxy))\n",
    "    if not A.is_integer():\n",
    "        raise ValueError(\"Invalid proxy vector\")\n",
    "    num_cands = int((1+A)/2)\n",
    "    \n",
    "    cand_pairs = list(combinations(range(1,num_cands+1),2))\n",
    "    ballot = [{num_cands}] # initialize ballot: bullet vote for last candidate\n",
    "\n",
    "    # We'll work through cand_pairs (i,j) in reverse order.  \n",
    "    # For 5 candidates, the order is (4,5) | (3,5), (3,4) | (2,5), (2,4), (2,3) | (1,5), (1,4), (1,3), (1,2)\n",
    "    # which breaks into groups for i = 4,3,2,1\n",
    "    # for each group, we add i to the top of the ballot, and then use the rest of the group's information to reposition i correctly\n",
    "    # (or return None if the rest of the group has inconsisent information).\n",
    "    for i in range(num_cands-1,0,-1):\n",
    "        group_indices = [x for x in range(len(cand_pairs)) if cand_pairs[x][0]==i]\n",
    "        left_of_i = [cand_pairs[x][1] for x in group_indices if proxy[x]<0]\n",
    "        right_of_i = [cand_pairs[x][1] for x in group_indices if proxy[x]>0]\n",
    "        match_i = [cand_pairs[x][1] for x in group_indices if proxy[x] == 0]\n",
    "        ballot_map = [] # has one entry {-1,0,+1} for each set in the ballot, indicating whether the set should be left, right, or containing i.\n",
    "        for c in ballot:\n",
    "            S = c if type(c) == set else {c}\n",
    "            if all(x in left_of_i for x in S):\n",
    "                ballot_map.append(-1)\n",
    "            elif all(x in right_of_i for x in S):\n",
    "                ballot_map.append(1)\n",
    "            elif all(x in match_i for x in S):\n",
    "                ballot_map.append(0)\n",
    "            else:\n",
    "                return None # inconsistent proxy\n",
    "            \n",
    "        zero_indices = [x for x in range(len(ballot_map)) if ballot_map[x]==0]\n",
    "        if (ballot_map != sorted(ballot_map)) or (len(zero_indices)>1):\n",
    "            return None # inconsistent proxy\n",
    "        \n",
    "        if len(zero_indices)==0:\n",
    "            insertion_index = len(ballot_map) if all(val <= 0 for val in ballot_map) else min([x for x in range(len(ballot_map)) if ballot_map[x] >=0])\n",
    "            ballot.insert(insertion_index,{i})\n",
    "        else:\n",
    "            insertion_index = zero_indices[0]\n",
    "            ballot[insertion_index] = ballot[insertion_index].union({i})\n",
    "    # return a simple ballot if possible\n",
    "    if all(len(c)==1 for c in ballot[:-1]):\n",
    "        return tuple([list(c)[0] for c in ballot if len(c)==1])\n",
    "    else:\n",
    "        return tuple(ballot)\n",
    "    \n",
    "def is_simple(ballot):\n",
    "    \"\"\"\n",
    "    Returns True if the given ballot is simple, False otherwise.\n",
    "    \"\"\"\n",
    "    return all(type(c)== int for c in ballot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the centers whenever only the proxies of the centers are given\n",
    "centers_list = []\n",
    "for index in df.index:\n",
    "    if df['centers'][index] == None:\n",
    "        proxies_of_centers = df['proxies_of_centers'][index]\n",
    "        if df['proxy'][index] == 'Borda':\n",
    "            centers = [Reverse_Borda(proxy) for proxy in proxies_of_centers]\n",
    "        elif df['proxy'][index] == 'HH':\n",
    "            centers = [Reverse_HH(proxy) for proxy in proxies_of_centers]\n",
    "    else:\n",
    "        centers = df['centers'][index]\n",
    "    centers_list.append(centers)\n",
    "\n",
    "df['centers'] = centers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find their proxies whenever only centers are given\n",
    "proxies_of_centers_list = []\n",
    "for index in df.index:\n",
    "    if df['proxies_of_centers'][index] == None:\n",
    "        centers = df['centers'][index]\n",
    "        if df['proxy'][index] == 'Borda':\n",
    "            proxies_of_centers = [Borda_proxy(center, num_cands=df['num_cands'][index]) for center in centers]\n",
    "        elif df['proxy'][index] == 'HH':\n",
    "            proxies_of_centers = [HH_proxy(center, num_cands=df['num_cands'][index]) for center in centers]\n",
    "    else:\n",
    "        proxies_of_centers = df['proxies_of_centers'][index]\n",
    "    proxies_of_centers_list.append(proxies_of_centers)\n",
    "df['proxies_of_centers'] = proxies_of_centers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_cands</th>\n",
       "      <th>method</th>\n",
       "      <th>proxy</th>\n",
       "      <th>technique</th>\n",
       "      <th>centers</th>\n",
       "      <th>proxies_of_centers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberdeen_2012_ward11.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>coords</td>\n",
       "      <td>Borda</td>\n",
       "      <td>coords_Borda</td>\n",
       "      <td>[(6, 1), ({4, 5}, {1, 2, 3, 6})]</td>\n",
       "      <td>[[3.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aberdeen_2012_ward11.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>coords</td>\n",
       "      <td>HH</td>\n",
       "      <td>coords_HH</td>\n",
       "      <td>[(6, 1), ({4, 5}, {1, 2, 3, 6})]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aberdeen_2012_ward11.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>all</td>\n",
       "      <td>Borda</td>\n",
       "      <td>all_Borda</td>\n",
       "      <td>[(4, 5), (6, 1)]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aberdeen_2012_ward11.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>all</td>\n",
       "      <td>HH</td>\n",
       "      <td>all_HH</td>\n",
       "      <td>[(6, 1), (4, 5)]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberdeen_2012_ward11.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>cast</td>\n",
       "      <td>HH</td>\n",
       "      <td>cast_HH</td>\n",
       "      <td>[(4, 5), (6, 1)]</td>\n",
       "      <td>[[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>west_lothian_2017_ward9.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>PAM</td>\n",
       "      <td>HH</td>\n",
       "      <td>PAM_HH</td>\n",
       "      <td>[(1, 4), (3,)]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>west_lothian_2022_ward1.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>Lloyd</td>\n",
       "      <td>Borda</td>\n",
       "      <td>Lloyd_Borda</td>\n",
       "      <td>[(4, 1, 5, 2, 6, 3), (5, 2, 3, 1, 6, 4)]</td>\n",
       "      <td>[[3.196907541811297, 1.6118649416219626, 0.262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>west_lothian_2022_ward1.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>Lloyd</td>\n",
       "      <td>HH</td>\n",
       "      <td>Lloyd_HH</td>\n",
       "      <td>[(4, 1, 5, 2, 3, 6), (5, 3, 2, 1, 6, 4)]</td>\n",
       "      <td>[[0.24813316739265662, 0.37741132545115036, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>west_lothian_2022_ward1.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>PAM</td>\n",
       "      <td>Borda</td>\n",
       "      <td>PAM_Borda</td>\n",
       "      <td>[(3, 5, 2), (4, 1, 5, 2)]</td>\n",
       "      <td>[[0, 3, 5, 0, 4, 0], [4, 2, 0, 5, 3, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>west_lothian_2022_ward1.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>PAM</td>\n",
       "      <td>HH</td>\n",
       "      <td>PAM_HH</td>\n",
       "      <td>[(4, 1), (5, 2, 3)]</td>\n",
       "      <td>[[1.0, 1.0, -1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  num_cands  method  proxy     technique  \\\n",
       "0        aberdeen_2012_ward11.csv          6  coords  Borda  coords_Borda   \n",
       "1        aberdeen_2012_ward11.csv          6  coords     HH     coords_HH   \n",
       "2        aberdeen_2012_ward11.csv          6     all  Borda     all_Borda   \n",
       "3        aberdeen_2012_ward11.csv          6     all     HH        all_HH   \n",
       "4        aberdeen_2012_ward11.csv          6    cast     HH       cast_HH   \n",
       "...                           ...        ...     ...    ...           ...   \n",
       "2046  west_lothian_2017_ward9.csv          6     PAM     HH        PAM_HH   \n",
       "2047  west_lothian_2022_ward1.csv          6   Lloyd  Borda   Lloyd_Borda   \n",
       "2048  west_lothian_2022_ward1.csv          6   Lloyd     HH      Lloyd_HH   \n",
       "2049  west_lothian_2022_ward1.csv          6     PAM  Borda     PAM_Borda   \n",
       "2050  west_lothian_2022_ward1.csv          6     PAM     HH        PAM_HH   \n",
       "\n",
       "                                       centers  \\\n",
       "0             [(6, 1), ({4, 5}, {1, 2, 3, 6})]   \n",
       "1             [(6, 1), ({4, 5}, {1, 2, 3, 6})]   \n",
       "2                             [(4, 5), (6, 1)]   \n",
       "3                             [(6, 1), (4, 5)]   \n",
       "4                             [(4, 5), (6, 1)]   \n",
       "...                                        ...   \n",
       "2046                            [(1, 4), (3,)]   \n",
       "2047  [(4, 1, 5, 2, 6, 3), (5, 2, 3, 1, 6, 4)]   \n",
       "2048  [(4, 1, 5, 2, 3, 6), (5, 3, 2, 1, 6, 4)]   \n",
       "2049                 [(3, 5, 2), (4, 1, 5, 2)]   \n",
       "2050                       [(4, 1), (5, 2, 3)]   \n",
       "\n",
       "                                     proxies_of_centers  \n",
       "0     [[3.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....  \n",
       "1     [[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....  \n",
       "2     [[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....  \n",
       "3     [[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....  \n",
       "4     [[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...  \n",
       "...                                                 ...  \n",
       "2046  [[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0.0...  \n",
       "2047  [[3.196907541811297, 1.6118649416219626, 0.262...  \n",
       "2048  [[0.24813316739265662, 0.37741132545115036, -0...  \n",
       "2049           [[0, 3, 5, 0, 4, 0], [4, 2, 0, 5, 3, 0]]  \n",
       "2050  [[1.0, 1.0, -1.0, 1.0, 1.0, 0.0, -1.0, 0.0, 0....  \n",
       "\n",
       "[2051 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'all' and 'cast' methods: verify that the centers are simple ballots that match the proxies \n",
    "\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    if not method in ['all', 'cast']:\n",
    "        continue\n",
    "    centers = df['centers'][index]\n",
    "    proxies_of_centers = df['proxies_of_centers'][index]\n",
    "    num_cands = df['num_cands'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "\n",
    "    bad = False\n",
    "    for i in [0,1]:\n",
    "        ballot = centers[i]\n",
    "        if not is_simple(ballot):\n",
    "            print(f\"{num_cands},{method},{proxy_type}: {ballot} is not simple\")\n",
    "        proxy_of_center = proxies_of_centers[i]\n",
    "        if proxy_type == 'Borda':\n",
    "            correct_proxy = Borda_proxy(ballot, num_cands, borda_style='pes')\n",
    "        else:\n",
    "            correct_proxy = HH_proxy(ballot, num_cands)\n",
    "            \n",
    "        if list(proxy_of_center) != list(correct_proxy):\n",
    "            print(f\"{num_cands},{method},{proxy_type}: {ballot} -> {list(correct_proxy)} != {list(proxy_of_center)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY for 'coords' method:\n",
      "simple match counts:\t {'Borda': 134, 'HH': 258}\n",
      "simple unmatch counts:\t {'Borda': 62, 'HH': 0}\n",
      "gen match counts:\t {'Borda': 169, 'HH': 59}\n",
      "gen unmatch counts:\t {'Borda': 45, 'HH': 0}\n",
      "none counts:\t\t {'Borda': 0, 'HH': 95}\n"
     ]
    }
   ],
   "source": [
    "# (for 'coords' method): for each proxy type, find portion of ballot proxies that \n",
    "# correspond to: simple ballots, generalized ballots, none.\n",
    "# For the simple and generalized categories, check if they exactly correspond to ballots.\n",
    "\n",
    "simple_match_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "simple_unmatch_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "gen_match_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "gen_unmatch_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "none_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    if method !='coords':\n",
    "        continue\n",
    "    centers = df['centers'][index]\n",
    "    proxies_of_centers = df['proxies_of_centers'][index]\n",
    "    num_cands = df['num_cands'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "\n",
    "    for i in [0,1]:\n",
    "        ballot = centers[i]\n",
    "        if ballot == None:\n",
    "            none_counts[proxy_type] += 1\n",
    "            continue\n",
    "        \n",
    "        is_this_simple = is_simple(ballot)\n",
    "        proxy_of_center = proxies_of_centers[i]\n",
    "        if proxy_type == 'Borda':\n",
    "            correct_proxy = Borda_proxy(ballot, num_cands, borda_style='pes')\n",
    "        else:\n",
    "            correct_proxy = HH_proxy(ballot, num_cands)\n",
    "        if list(proxy_of_center) == list(correct_proxy):\n",
    "            if is_this_simple:\n",
    "                simple_match_counts[proxy_type] += 1\n",
    "            else:\n",
    "                gen_match_counts[proxy_type] += 1\n",
    "        else:\n",
    "            if is_this_simple:\n",
    "                simple_unmatch_counts[proxy_type] += 1\n",
    "            else:\n",
    "                gen_unmatch_counts[proxy_type] += 1\n",
    "\n",
    "print(\"SUMMARY for 'coords' method:\")\n",
    "print(f'simple match counts:\\t {simple_match_counts}')\n",
    "print(f'simple unmatch counts:\\t {simple_unmatch_counts}') \n",
    "print(f'gen match counts:\\t {gen_match_counts}')\n",
    "print(f'gen unmatch counts:\\t {gen_unmatch_counts}')\n",
    "print(f'none counts:\\t\\t {none_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATIONS:\n",
    "\n",
    "$95$ of the $205\\cdot 2= 410$ HH proxy vectors are inconsistent (have loops like A>B>C>A).  Of the rest, $258$ pull back to simple ballots and $59$ to generalized ballots.  For a sanity check, we verified that these are uniquely determined by the (simple or generalized) ballot to which they pull back.\n",
    "\n",
    "About half ($214$) of the Borda proxies have ties (multiple occurances of the same number, other than in last place), so they correspond to generalized (rather than simple) ballots.  About a quarter of the Borda proxies aren't valid proxies of actual ballots, since component-wise medians don't necessarily follow the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY for 'kMedians' method:\n",
      "simple match counts:\t {'Borda': 407, 'HH': 405}\n",
      "simple unmatch counts:\t {'Borda': 2, 'HH': 0}\n",
      "gen match counts:\t {'Borda': 0, 'HH': 4}\n",
      "gen unmatch counts:\t {'Borda': 1, 'HH': 0}\n",
      "none counts:\t\t {'Borda': 0, 'HH': 1}\n"
     ]
    }
   ],
   "source": [
    "# Do same for 'kMedians' method\n",
    "\n",
    "simple_match_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "simple_unmatch_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "gen_match_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "gen_unmatch_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "none_counts = {proxy:0 for proxy in ['Borda','HH']}\n",
    "\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    if method !='kMedians':\n",
    "        continue\n",
    "    centers = df['centers'][index]\n",
    "    proxies_of_centers = df['proxies_of_centers'][index]\n",
    "    num_cands = df['num_cands'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "\n",
    "    for i in [0,1]:\n",
    "        ballot = centers[i]\n",
    "        if ballot == None:\n",
    "            none_counts[proxy_type] += 1\n",
    "            continue\n",
    "        \n",
    "        is_this_simple = is_simple(ballot)\n",
    "        proxy_of_center = proxies_of_centers[i]\n",
    "        if proxy_type == 'Borda':\n",
    "            correct_proxy = Borda_proxy(ballot, num_cands, borda_style='pes')\n",
    "        else:\n",
    "            correct_proxy = HH_proxy(ballot, num_cands)\n",
    "        if list(proxy_of_center) == list(correct_proxy):\n",
    "            if is_this_simple:\n",
    "                simple_match_counts[proxy_type] += 1\n",
    "            else:\n",
    "                gen_match_counts[proxy_type] += 1\n",
    "        else:\n",
    "            if is_this_simple:\n",
    "                simple_unmatch_counts[proxy_type] += 1\n",
    "            else:\n",
    "                gen_unmatch_counts[proxy_type] += 1\n",
    "print(\"SUMMARY for 'kMedians' method:\")\n",
    "print(f'simple match counts:\\t {simple_match_counts}')\n",
    "print(f'simple unmatch counts:\\t {simple_unmatch_counts}') \n",
    "print(f'gen match counts:\\t {gen_match_counts}')\n",
    "print(f'gen unmatch counts:\\t {gen_unmatch_counts}')\n",
    "print(f'none counts:\\t\\t {none_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elections with uncast centers\n"
     ]
    }
   ],
   "source": [
    "# for each proxy method, determine the portion of elections for which the 'all' centers \n",
    "# correspond to ballots that were actually cast in the election.\n",
    "\n",
    "elections_with_uncast_centers = []\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    proxy = df['proxy'][index]\n",
    "    if method != 'all':\n",
    "        continue\n",
    "    centers = df['centers'][index]\n",
    "    proxies_of_centers = df['proxies_of_centers'][index]\n",
    "    num_cands = df['num_cands'][index]\n",
    "    filename = df['filename'][index]\n",
    "    full_filename = f\"../ballot-clustering/scot-elex/{num_cands}_cands/{filename}\"\n",
    "    num_cands, election, cand_names, ward = csv_parse(full_filename)\n",
    "    if not (centers[0] in election.keys() and centers[1] in election.keys()):\n",
    "        print(f\"{filename}({proxy}) has centers {centers} that don't correspond to actual ballots\")\n",
    "        print(proxies_of_centers)\n",
    "        elections_with_uncast_centers.append((filename, proxy, centers, proxies_of_centers))\n",
    "print(len(elections_with_uncast_centers), \"elections with uncast centers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "\n",
    "The 'all' method always produces cast centers, so the method isn't really more general, at least among 6-candidate elections.\n",
    "\n",
    "But for more candidates, there are examples where $()$ is a center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Borda': 1.0, 'HH': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How frequently do 'cast' centers match 'all' centers?  \n",
    "\n",
    "good_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "bad_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "\n",
    "for index in df.index:\n",
    "    if df['method'][index] != 'all':\n",
    "        continue\n",
    "    filename = df['filename'][index]\n",
    "    rest_centers = df['centers'][index]\n",
    "    proxy = df['proxy'][index]\n",
    "    row_index = df[(df['filename'] == filename) & (df['technique'] == f'cast_{proxy}')].index[0]\n",
    "    discrete_centers = df['centers'][row_index]\n",
    "    if set(rest_centers) != set(discrete_centers):\n",
    "        #print(f\"{filename} ({proxy}): {rest_centers[0],rest_centers[1]} != {discrete_centers[0],discrete_centers[1]}\")\n",
    "        bad_counts[proxy] += 1\n",
    "    else:\n",
    "        good_counts[proxy] += 1\n",
    "\n",
    "# portion of the elections for which the 'all' centers match the 'cast' centers\n",
    "good_counts = {proxy:count for proxy,count in good_counts.items()}\n",
    "bad_counts = {proxy:count for proxy,count in bad_counts.items() }\n",
    "{proxy:good_counts[proxy]/(good_counts[proxy]+bad_counts[proxy]) for proxy in good_counts.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "\n",
    "The 'cast' centers always match the 'all' centers, even though there are presumably tied solutions that might be found.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the score (summed L^1 distance of the ballots to the nearest center) for all the methods and all proxies.\n",
    "# and rebuild all of the clusterings from the centers.\n",
    "score_list = []\n",
    "clusters_list = []\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    proxy = df['proxy'][index]\n",
    "    filename = df['filename'][index]\n",
    "    num_cands = df['num_cands'][index]\n",
    "    full_filename = f\"../ballot-clustering/scot-elex/{num_cands}_cands/{filename}\"\n",
    "    num_cands, election, cand_names, ward = csv_parse(full_filename)\n",
    "\n",
    "    centers = df['proxies_of_centers'][index]\n",
    "    order = 2 if method == 'Lloyd' else 1\n",
    "\n",
    "    score, clustering = Clusters_from_centers(election, centers, proxy, order=order, \n",
    "                                              centers_live_in_proxy_space=True)\n",
    "    score_list.append(score)\n",
    "    clusters_list.append(clustering)\n",
    "df['score'] = score_list\n",
    "df['clustering'] = clusters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All scores match!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Verify that the computed score matches the one from the IP solver dataframe dfIP.\n",
    "D_IP_reverse = {v:k for k,v in D_IP.items()}\n",
    "\n",
    "IP_techniques = ['coords_Borda', 'coords_HH', 'all_Borda', 'all_HH', 'cast_HH', 'cast_Borda']\n",
    "Good_counts = {technique:0 for technique in IP_techniques}\n",
    "Bad_counts = {technique:0 for technique in IP_techniques}\n",
    "\n",
    "for index in df.index:\n",
    "    method = df['method'][index]\n",
    "    proxy = df['proxy'][index]\n",
    "    filename = df['filename'][index]\n",
    "    technique = df['technique'][index]\n",
    "    if method not in ['all', 'cast', 'coords']:\n",
    "        continue\n",
    "    row_index = dfIP[(dfIP['election_name'] == filename[:-4]) & (dfIP['model'] == D_IP_reverse[(method, proxy)])].index[0]\n",
    "    IP_score = dfIP['optimum_value'][row_index]\n",
    "    if method in ['all', 'coords'] or technique == 'cast_Borda':\n",
    "        IP_score *= (1/2) # divide by 2 to match our score definition as half the L^1 distance\n",
    "    computed_score = df['score'][index]\n",
    "    if abs(IP_score - computed_score) > 1e-6:\n",
    "        print(f\"Score mismatch for {filename}, ({technique}): ratio ={IP_score/computed_score}\")\n",
    "        Bad_counts[technique] += 1\n",
    "    else:   \n",
    "        Good_counts[technique] += 1\n",
    "        \n",
    "if sum(Bad_counts.values()) == 0:\n",
    "    print(\"All scores match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>centers</th>\n",
       "      <th>proxies_of_centers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coords_Borda</td>\n",
       "      <td>[(6, 1), ({4, 5}, {1, 2, 3, 6})]</td>\n",
       "      <td>[[3.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....</td>\n",
       "      <td>16414.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coords_HH</td>\n",
       "      <td>[(6, 1), ({4, 5}, {1, 2, 3, 6})]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....</td>\n",
       "      <td>16817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_Borda</td>\n",
       "      <td>[(4, 5), (6, 1)]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....</td>\n",
       "      <td>16617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_HH</td>\n",
       "      <td>[(6, 1), (4, 5)]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....</td>\n",
       "      <td>16843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cast_HH</td>\n",
       "      <td>[(4, 5), (6, 1)]</td>\n",
       "      <td>[[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...</td>\n",
       "      <td>16843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cast_Borda</td>\n",
       "      <td>[(4, 5), (6, 1)]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....</td>\n",
       "      <td>16617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>PAM_Borda</td>\n",
       "      <td>[(6, 1), (4, 5)]</td>\n",
       "      <td>[[4, 0, 0, 0, 0, 5], [0, 0, 0, 5, 4, 0]]</td>\n",
       "      <td>16617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>PAM_HH</td>\n",
       "      <td>[(6, 1), (4, 5)]</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....</td>\n",
       "      <td>16843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>kMedians_Borda</td>\n",
       "      <td>[(6, 1), (4, 5)]</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....</td>\n",
       "      <td>16617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>kMedians_HH</td>\n",
       "      <td>[(5, 4), (6,)]</td>\n",
       "      <td>[[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...</td>\n",
       "      <td>16924.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           technique                           centers  \\\n",
       "0       coords_Borda  [(6, 1), ({4, 5}, {1, 2, 3, 6})]   \n",
       "1          coords_HH  [(6, 1), ({4, 5}, {1, 2, 3, 6})]   \n",
       "2          all_Borda                  [(4, 5), (6, 1)]   \n",
       "3             all_HH                  [(6, 1), (4, 5)]   \n",
       "4            cast_HH                  [(4, 5), (6, 1)]   \n",
       "5         cast_Borda                  [(4, 5), (6, 1)]   \n",
       "1233       PAM_Borda                  [(6, 1), (4, 5)]   \n",
       "1234          PAM_HH                  [(6, 1), (4, 5)]   \n",
       "2051  kMedians_Borda                  [(6, 1), (4, 5)]   \n",
       "2052     kMedians_HH                    [(5, 4), (6,)]   \n",
       "\n",
       "                                     proxies_of_centers    score  \n",
       "0     [[3.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....  16414.5  \n",
       "1     [[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....  16817.0  \n",
       "2     [[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....  16617.0  \n",
       "3     [[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....  16843.0  \n",
       "4     [[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...  16843.0  \n",
       "5     [[0.0, 0.0, 0.0, 5.0, 4.0, 0.0], [4.0, 0.0, 0....  16617.0  \n",
       "1233           [[4, 0, 0, 0, 0, 5], [0, 0, 0, 5, 4, 0]]  16617.0  \n",
       "1234  [[1.0, 1.0, 1.0, 1.0, -1.0, 0.0, 0.0, 0.0, -1....  16843.0  \n",
       "2051  [[4.0, 0.0, 0.0, 0.0, 0.0, 5.0], [0.0, 0.0, 0....  16617.0  \n",
       "2052  [[0.0, 0.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0, ...  16924.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at one election in detail\n",
    "filename = 'aberdeen_2012_ward11.csv'\n",
    "full_filename = f\"../ballot-clustering/scot-elex/{num_cands}_cands/{filename}\"\n",
    "num_cands, election, cand_names, ward = csv_parse(full_filename)\n",
    "test = df[(df['filename'] == filename) & (df['method'] != 'Lloyd')][['technique', 'centers', 'proxies_of_centers', 'score']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 45)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election[(6,1)], election[(4,5)] # check that both were cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIE:  east_dunbartonshire_2017_ward5.csv HH\n",
      "match: {'Borda': 189, 'HH': 194}\n",
      "unmatch but tie: {'Borda': 0, 'HH': 1}\n",
      "PAM win: {'Borda': 0, 'HH': 0}\n",
      "\"cast\" win: {'Borda': 16, 'HH': 10}\n"
     ]
    }
   ],
   "source": [
    "# find portion of elections for which the cast centers match the PAM centers\n",
    "# when they don't, check whether the cast centers tie or score better.\n",
    "match_count = {'Borda':0, 'HH':0}\n",
    "unmatch_count = {'Borda':0, 'HH':0}\n",
    "\n",
    "tie_count = {'Borda':0, 'HH':0}\n",
    "PAM_win_count = {'Borda':0, 'HH':0}\n",
    "cast_win_count = {'Borda':0, 'HH':0}\n",
    "\n",
    "row_index = 0\n",
    "for index in df.index:\n",
    "    if df['method'][index] != 'cast':\n",
    "        continue\n",
    "    discrete_centers = df['centers'][index]\n",
    "    discrete_score = df['score'][index]\n",
    "    filename = df['filename'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "    row_index = df[(df['filename'] == filename) & (df['technique'] == f'PAM_{proxy_type}')].index[0]\n",
    "    PAM_score = df['score'][row_index]\n",
    "    PAM_centers = df['centers'][row_index]\n",
    "    if set(PAM_centers) == set(discrete_centers):\n",
    "        match_count[proxy_type] += 1\n",
    "        continue\n",
    "    else:\n",
    "        unmatch_count[proxy_type] += 1\n",
    "    \n",
    "    if discrete_score == PAM_score:\n",
    "        tie_count[proxy_type] += 1\n",
    "        print(\"TIE: \",filename, proxy_type)\n",
    "    elif discrete_score < PAM_score:\n",
    "        cast_win_count[proxy_type] += 1\n",
    "    else:\n",
    "        PAM_win_count[proxy_type] += 1\n",
    "        print(proxy_type, discrete_score, PAM_score, discrete_centers, PAM_centers)\n",
    "\n",
    "print(f'match: {match_count}')\n",
    "print(f'unmatch but tie: {tie_count}')\n",
    "print(f'PAM win: {PAM_win_count}')\n",
    "print(f'\"cast\" win: {cast_win_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>centers</th>\n",
       "      <th>score</th>\n",
       "      <th>clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>cast_HH</td>\n",
       "      <td>[(4, 5, 1), (3, 6, 2)]</td>\n",
       "      <td>19880.0</td>\n",
       "      <td>{0: {(1,): 43.0, (1, 2): 5.0, (1, 2, 4): 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>PAM_HH</td>\n",
       "      <td>[(2, 3, 6), (4, 5, 1)]</td>\n",
       "      <td>19880.0</td>\n",
       "      <td>{0: {(1, 2): 5.0, (1, 2, 3): 3.0, (1, 2, 3, 6)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     technique                 centers    score  \\\n",
       "370    cast_HH  [(4, 5, 1), (3, 6, 2)]  19880.0   \n",
       "1478    PAM_HH  [(2, 3, 6), (4, 5, 1)]  19880.0   \n",
       "\n",
       "                                             clustering  \n",
       "370   {0: {(1,): 43.0, (1, 2): 5.0, (1, 2, 4): 2.0, ...  \n",
       "1478  {0: {(1, 2): 5.0, (1, 2, 3): 3.0, (1, 2, 3, 6)...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the one election in which PAM and 'cast' tie but don't match\n",
    "filename = 'east_dunbartonshire_2017_ward5.csv'\n",
    "full_filename = f\"../ballot-clustering/scot-elex/{num_cands}_cands/{filename}\"\n",
    "num_cands, election, cand_names, ward = csv_parse(full_filename)\n",
    "test = df[(df['filename'] == filename) & (df['technique'].isin(['cast_HH', 'PAM_HH']))][['technique', 'centers', 'score', 'clustering']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = test['clustering'][370]\n",
    "C2 = test['clustering'][1478]\n",
    "Clustering_closeness(election, C1, C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPETATION:\n",
    "\n",
    "PAM centers match 'cast' centers over $90\\%$ of the time.  When they don't match, there's only one election (with HH) for which the reason is that they find different tied optimum (the centers are slightly different and result in slightly different clusterings).  For the rest, it's because 'cast' beats PAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Borda': 22, 'HH': 78}, {'Borda': 183, 'HH': 128}, {'Borda': 0, 'HH': 0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the portion of the elections for which the continous score beats the cast score\n",
    "tie_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "continuous_win_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "discrete_win_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "\n",
    "for index in df.index:\n",
    "    if df['method'][index] != 'coords':\n",
    "        continue\n",
    "    filename = df['filename'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "    continuous_score = df['score'][index]\n",
    "    row_index = df[(df['filename'] == filename) & (df['technique'] == f'cast_{proxy_type}')].index[0]\n",
    "    discrete_score = df['score'][row_index]\n",
    "\n",
    "    if continuous_score == discrete_score:\n",
    "        tie_counts[proxy_type] += 1\n",
    "    elif continuous_score < discrete_score:\n",
    "        continuous_win_counts[proxy_type] += 1\n",
    "    else:\n",
    "        discrete_win_counts[proxy_type] += 1\n",
    "\n",
    "tie_counts, continuous_win_counts, discrete_win_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tie with same proxies: {'Borda': 5, 'HH': 15}\n",
      "tie with different proxies: {'Borda': 0, 'HH': 0}\n",
      "continuous win: {'Borda': 200, 'HH': 191}\n",
      "kMedians win: {'Borda': 0, 'HH': 0}\n"
     ]
    }
   ],
   "source": [
    "# determine the portion of the elections for which the continous score beats the kMedians score\n",
    "tie_with_same_proxies_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "tie_with_different_proxies_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "continuous_win_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "kMedians_win_counts = {proxy:0 for proxy in ['Borda', 'HH']}\n",
    "\n",
    "for index in df.index:\n",
    "    if df['method'][index] != 'coords':\n",
    "        continue\n",
    "    filename = df['filename'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "    continuous_score = df['score'][index]\n",
    "    row_index = df[(df['filename'] == filename) & (df['technique'] == f'kMedians_{proxy_type}')].index[0]\n",
    "    kmed_score = df['score'][row_index]\n",
    "\n",
    "    if continuous_score == kmed_score:\n",
    "        if set(map(tuple, df['proxies_of_centers'][index])) == set(map(tuple, df['proxies_of_centers'][row_index])):\n",
    "            tie_with_same_proxies_counts[proxy_type] += 1\n",
    "        else:\n",
    "            tie_with_different_proxies_counts[proxy_type] += 1\n",
    "    elif continuous_score < kmed_score:\n",
    "        continuous_win_counts[proxy_type] += 1\n",
    "    else:\n",
    "        kMedians_win_counts[proxy_type] += 1\n",
    "print(f'tie with same proxies: {tie_with_same_proxies_counts}')\n",
    "print(f'tie with different proxies: {tie_with_different_proxies_counts}') \n",
    "print(f'continuous win: {continuous_win_counts}')\n",
    "print(f'kMedians win: {kMedians_win_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure clustering closness of the cast vs continuous methods\n",
    "closeness = {proxy:[] for proxy in ['Borda', 'HH']}\n",
    "errors = 0\n",
    "\n",
    "for index in df.index:\n",
    "    if df['method'][index] != 'coords':\n",
    "        continue\n",
    "    filename = df['filename'][index]\n",
    "    proxy_type = df['proxy'][index]\n",
    "    C_continuous = df['clustering'][index]\n",
    "    row_index = df[(df['filename'] == filename) & (df['technique'] == f'cast_{proxy_type}')].index[0]\n",
    "    C_discrete = df['clustering'][row_index]\n",
    "\n",
    "    num_cands = df['num_cands'][index]\n",
    "    full_filename = f\"../ballot-clustering/scot-elex/{num_cands}_cands/{filename}\"\n",
    "    _, election, __, ____ = csv_parse(full_filename)\n",
    "    try:\n",
    "        closeness[proxy_type].append(Clustering_closeness(election, C_continuous, C_discrete))\n",
    "    except:\n",
    "        errors += 1\n",
    "        print(proxy, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Borda': 0.03241625811392328, 'HH': 0.02020563301256821}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{proxy: np.mean(closeness[proxy]) for proxy in closeness.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
